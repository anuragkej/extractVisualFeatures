{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.40.0 in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.40.0)\n",
      "Requirement already satisfied: torch==2.3.0 in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: torchvision==0.18.0 in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: einops in ./.conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.8.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoFeatureExtractor\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "imageBirdURL = \"https://static.inaturalist.org/photos/405494470/original.jpeg\"\n",
    "imageFlowerURL = (\n",
    "    \"https://inaturalist-open-data.s3.amazonaws.com/photos/405552903/original.jpeg\"\n",
    ")\n",
    "\n",
    "responseBird = requests.get(imageBirdURL)\n",
    "responseFlower = requests.get(imageFlowerURL)\n",
    "\n",
    "imageBird = Image.open(BytesIO(responseBird.content))\n",
    "imageFlower = Image.open(BytesIO(responseFlower.content))\n",
    "\n",
    "# vision transformer ViT\n",
    "featureExtract = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "resizeBird = featureExtract(\n",
    "    images=imageBird, size=(100, 100), return_tensors=\"pt\"\n",
    ").pixel_values\n",
    "resizeFlower = featureExtract(\n",
    "    images=imageFlower, size=(100, 100), return_tensors=\"pt\"\n",
    ").pixel_values\n",
    "\n",
    "resized_image_Bird = Image.fromarray(\n",
    "    (resizeBird[0].permute(1, 2, 0) * 255).byte().numpy()\n",
    ")\n",
    "resized_image_Bird.save(\"resized_image_bird.jpg\")\n",
    "resized_image_Flower = Image.fromarray(\n",
    "    (resizeFlower[0].permute(1, 2, 0) * 255).byte().numpy()\n",
    ")\n",
    "resized_image_Flower.save(\"resized_image_flower.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
